{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc950a53",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "090d8719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:25.305177Z",
     "start_time": "2023-02-25T05:31:25.299312Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from glob import glob\n",
    "from typing import Dict, List, Tuple, Type\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from botocore.exceptions import ClientError\n",
    "from sympy.combinatorics import Permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543f4e4",
   "metadata": {},
   "source": [
    "## Add configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f0f02287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:25.677299Z",
     "start_time": "2023-02-25T05:31:25.674026Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/jovyan/core/config/\")\n",
    "sys.path.append(\"/home/jovyan/core/util/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "08c511e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:25.830326Z",
     "start_time": "2023-02-25T05:31:25.824874Z"
    }
   },
   "outputs": [],
   "source": [
    "from ALL import config \n",
    "from util import *\n",
    "# from MultilayerDict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe2603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b43d85a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:26.121978Z",
     "start_time": "2023-02-25T05:31:26.116622Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_bucket_name =  \"text-classification-nakayama-bucket\"\n",
    "object_name = \"RawData/reuters/\"\n",
    "root_path = \"/home/jovyan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ef5c1ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:26.289041Z",
     "start_time": "2023-02-25T05:31:26.282053Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {\"temporary\": {\"A\": \"doc\", \"B\": \"tes\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bd97b587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:26.433344Z",
     "start_time": "2023-02-25T05:31:26.429517Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"/home/jovyan/temporary/test/0/0/test.csv\"\n",
    "dir_path = \"../../temporary/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3e89ad12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:26.591572Z",
     "start_time": "2023-02-25T05:31:26.588626Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding=\"utf8\"\n",
    "newline=\"\"\n",
    "delimiter=\",\"\n",
    "quotechar=\"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa00c772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:26.757583Z",
     "start_time": "2023-02-25T05:31:26.751434Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _make_test(\n",
    "    file_data: pd.DataFrame,\n",
    "    file_num: int = 2,\n",
    "    file_depth: int = 2,\n",
    "    extension: str = \"csv\",\n",
    "):\n",
    "    _file_nums = [str(_file_num) for _file_num in range(file_num)]\n",
    "\n",
    "    for _file_name in itertools.product(_file_nums, repeat=file_depth):\n",
    "        _file_path = f\"{root_path_temporary}/test/{'/'.join(_file_name)}/test.{extension}\"\n",
    "        file_data.to_csv(make_filepath(_file_path), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4fb97797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:26.918333Z",
     "start_time": "2023-02-25T05:31:26.908350Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame([[1, 2, 3, 4 ], [2, 3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ff00ebdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:27.091282Z",
     "start_time": "2023-02-25T05:31:27.072143Z"
    }
   },
   "outputs": [],
   "source": [
    "_make_test(test_df, file_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e47d2025",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:27.232542Z",
     "start_time": "2023-02-25T05:31:27.229605Z"
    }
   },
   "outputs": [],
   "source": [
    "field_names= [\"a\", \"b\", \"c\"]\n",
    "index=[\"dim1\", \"dim2\", \"dim3\", \"dim4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7576a4f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:31:27.388987Z",
     "start_time": "2023-02-25T05:31:27.385426Z"
    }
   },
   "outputs": [],
   "source": [
    "names_keys = {\"col\": field_names, \"ind\": index, \"ind2\": [1, 2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "19e9e3d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:41.022511Z",
     "start_time": "2023-02-25T05:38:40.985557Z"
    },
    "code_folding": [
     86,
     96,
     180,
     247
    ]
   },
   "outputs": [],
   "source": [
    "class MultilayerDict:\n",
    "    \"\"\"\n",
    "    MultilayerDict\n",
    "    \"\"\"\n",
    "\n",
    "    names: List\n",
    "    names_keys: Dict\n",
    "    dictionary: Dict\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        names_keys: Dict | None = None,\n",
    "        dictionary: Dict | None = None,\n",
    "        dir_path: str | None = None,\n",
    "        names: List | None = None,\n",
    "        extension: str = \"csv\",\n",
    "        basis_depth: str = \"max\",\n",
    "    ):\n",
    "        if names_keys is not None:\n",
    "            self.names = list(names_keys.keys())\n",
    "            self.names_keys = names_keys\n",
    "            if dictionary is not None:\n",
    "                self.dictionary = dictionary\n",
    "            else:\n",
    "                self.dictionary = self.make_multilayer_dict(list(names_keys.values()))\n",
    "        elif dir_path is not None:\n",
    "            self.dictionary, _keys, self.names = self.read_dirs(\n",
    "                dir_path,\n",
    "                names=names,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Both names_keys and dir_path are None.\")\n",
    "\n",
    "    def __check_all_none(self, *args) -> bool:\n",
    "        if all(_v is None for _v in args):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def __check_one_not_none(self, *args) -> bool:\n",
    "        if sum(1 for arg in args if arg is not None) == 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def make_multilayer_dict(self, keys: List):\n",
    "        def _multilayer_dict_recursive(_d: Dict, _keys: List):\n",
    "            if not _keys:\n",
    "                return _d, []\n",
    "            else:\n",
    "                return _multilayer_dict_recursive(\n",
    "                    {_key: copy.deepcopy(_d) for _key in _keys[-1]}, _keys[:-1]\n",
    "                )\n",
    "\n",
    "        _multilayer_dict, _ = _multilayer_dict_recursive(dict(), keys)\n",
    "        return _multilayer_dict\n",
    "\n",
    "    def name_is_in(self, name) -> bool:\n",
    "        return name in self.name\n",
    "\n",
    "    def keys_exist(self, keys: List | Tuple) -> bool:\n",
    "        def __is_accessible(_d: Dict, _t: List | Tuple) -> bool:\n",
    "            if len(_t) == 1:\n",
    "                return _t[0] in _d\n",
    "            if _t[0] in _d:\n",
    "                return __is_accessible(_d[_t[0]], _t[1:])\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        return __is_accessible(self.dictionary, keys)\n",
    "\n",
    "    def loc(self, key_list: List):\n",
    "        def _loc_recursive(_val, _key_list: list):\n",
    "            if not _key_list:\n",
    "                return _val\n",
    "            else:\n",
    "                return _loc_recursive(_val[_key_list[0]], _key_list[1:])\n",
    "\n",
    "        return _loc_recursive(self.dictionary, key_list)\n",
    "\n",
    "    def update(self, key_list: List, val) -> None:\n",
    "        _d = self.dictionary\n",
    "        for key in key_list[:-1]:\n",
    "            _d = _d[key]\n",
    "        _d[key_list[-1]] = val\n",
    "\n",
    "    def read_dirs(self, dir_path, names=None, extension=\"csv\", basis_depth=\"max\"):\n",
    "        def _one_dimensional_csv_to_dict(\n",
    "            file_path, encoding=\"utf8\", newline=\"\", delimiter=\",\", quotechar=\"|\"\n",
    "        ):\n",
    "            print(file_path)\n",
    "            with open(file_path, mode=\"r\", encoding=encoding, newline=newline) as _f:\n",
    "                _reader = csv.reader(_f, delimiter=delimiter, quotechar=quotechar)\n",
    "                _dict = dict(_reader)\n",
    "            return _dict\n",
    "\n",
    "        def _one_dimensional_json_to_dict(\n",
    "            file_path,\n",
    "            encoding=\"utf8\",\n",
    "            newline=\"\",\n",
    "        ):\n",
    "            with open(file_path, mode=\"r\", encoding=encoding, newline=newline) as _f:\n",
    "                _dict = json.load(_f)\n",
    "            return _dict\n",
    "\n",
    "        def _get_uniform_dirs(__path_dirs, _basis_depth):\n",
    "            # 最も深いパスを基準にMultilayerDictを生成する\n",
    "            if _basis_depth == \"max\":\n",
    "                _depth = max(map(len, __path_dirs.values()))\n",
    "                _uniform_dirs = {\n",
    "                    _path: _dir\n",
    "                    for _path, _dir in __path_dirs.items()\n",
    "                    if len(_dir) == _depth\n",
    "                }\n",
    "                return _depth, _uniform_dirs\n",
    "            elif _basis_depth == \"min\":\n",
    "                _depth = min(map(len, __path_dirs.values()))\n",
    "                _uniform_dirs = {\n",
    "                    _path: _dir\n",
    "                    for _path, _dir in __path_dirs.items()\n",
    "                    if len(_dir) == _depth\n",
    "                }\n",
    "                return _depth, _uniform_dirs\n",
    "            elif isinstance(_basis_depth, int) & (_basis_depth > 0):\n",
    "                _depth = _basis_depth\n",
    "                _uniform_dirs = {\n",
    "                    _path: _dir\n",
    "                    for _path, _dir in __path_dirs.items()\n",
    "                    if len(_dir) == _depth\n",
    "                }\n",
    "                return _depth, _uniform_dirs\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        # 読み込みディレクトリの中のファイルパスを探索し,ファイルパスからdictのkeyを生成\n",
    "        _path_dirs = {}\n",
    "        _abs_dir_path = os.path.abspath(dir_path)\n",
    "        for _root, _, _file_names in os.walk(_abs_dir_path, followlinks=True):\n",
    "            if _file_names:\n",
    "                for _file_name in _file_names:\n",
    "                    _file_path = f\"{_root}/{_file_name}\"\n",
    "                    _file_name = os.path.splitext(os.path.basename(_file_name))[0]\n",
    "                    _path_dirs[_file_path] = (\n",
    "                        _file_path.replace(_abs_dir_path, \"\")\n",
    "                    ).split(\"/\")[1:]\n",
    "\n",
    "        _depth, _uniform_path_dirs = _get_uniform_dirs(_path_dirs, basis_depth)\n",
    "\n",
    "        # ファイルの読み込み\n",
    "        _file_keys = set()\n",
    "        if extension == \"csv\":\n",
    "            for _path, _dir_list in _uniform_path_dirs.items():\n",
    "                print(_path)\n",
    "                print(_dir_list)\n",
    "                _file_dict = _one_dimensional_csv_to_dict(_path)\n",
    "                md.update(_dir_list, _file_dict)\n",
    "                _file_keys = _file_keys & set(_file_dict)\n",
    "        elif extension == \"json\":\n",
    "            for _path, _dir_list in _uniform_path_dirs.items():\n",
    "                _file_dict = _one_dimensional_json_to_dict(_path)\n",
    "                md.update(_dir_list, _file_dict)\n",
    "                _file_keys = _file_keys & set(_file_dict)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        _keys = [list(set(_)) for _ in zip(*_uniform_path_dirs.values())]\n",
    "        _keys.append(_file_keys)\n",
    "\n",
    "        if names:\n",
    "            _names = range(_depth + 1)\n",
    "        else:\n",
    "            if len(names) == _depth + 1:\n",
    "                _names = names\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"length mismatch. basis_depth is {basis_depth}, but length of name is {len(names)}.\"\n",
    "                )\n",
    "        _md = self.make_multilayer_dict(_names)\n",
    "        return _md, _keys, _names\n",
    "\n",
    "    def drop_names(\n",
    "        self, names: List | None = None, loc: int | None = None, inplace: bool = False\n",
    "    ):\n",
    "        if self.__check_all_none(names, loc):\n",
    "            raise ValueError(\"At least one argument must not be None.\")\n",
    "\n",
    "        if not self.__check_one_not_none(names, loc):\n",
    "            raise ValueError(\"Multiple variables are specified.\")\n",
    "\n",
    "        if names is not None:\n",
    "            if self.names[-len(names) :] != names:\n",
    "                raise ValueError(\n",
    "                    f\"The given names ({names}) do not match the variable ({self.names}).\"\n",
    "                )\n",
    "            if inplace:\n",
    "                self.names = [_ for _ in self.names[: -len(names)]]\n",
    "                self.names_keys = {\n",
    "                    _name: _val\n",
    "                    for _name, _val in self.names_keys.items()\n",
    "                    if _name in self.names\n",
    "                }\n",
    "            else:\n",
    "                _names = [_ for _ in self.names[: -len(names)]]\n",
    "                _names_keys = {\n",
    "                    _name: _val\n",
    "                    for _name, _val in self.names_keys.items()\n",
    "                    if _name in _names\n",
    "                }\n",
    "                _dictionary = copy.deepcopy(self.dictionary)\n",
    "                return MultilayerDict(_names_keys, _dictionary)\n",
    "\n",
    "        elif loc is not None:\n",
    "            if len(self.names_keys) < loc:\n",
    "                raise ValueError(\n",
    "                    f\"Value of loc ({loc}) exceed length of names ({len(self.names_keys)})\"\n",
    "                )\n",
    "            if inplace:\n",
    "                self.names = [_ for _ in self.names[:-loc]]\n",
    "                self.names_keys = {\n",
    "                    _name: _val\n",
    "                    for _name, _val in self.names_keys.items()\n",
    "                    if _name in self.names\n",
    "                }\n",
    "            else:\n",
    "                _names = [_ for _ in self.names[:-loc]]\n",
    "                _names_keys = {\n",
    "                    _name: _val\n",
    "                    for _name, _val in self.names_keys.items()\n",
    "                    if _name in _names\n",
    "                }\n",
    "                _dictionary = copy.deepcopy(self.dictionary)\n",
    "                return MultilayerDict(_names_keys, _dictionary)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def add_names(self, names_keys: Dict, inplace: bool = False):\n",
    "        _new_names_keys = dict(**self.names_keys, **names_keys)\n",
    "        for _keys in itertools.product(*_new_names_keys.values()):\n",
    "            if not self.keys_exist(_keys):\n",
    "                raise KeyError(f\"The key does not exist {_keys}.\")\n",
    "        if inplace:\n",
    "            self.names_keys = _new_names_keys\n",
    "            self.names = list(_new_names_keys.keys())\n",
    "        else:\n",
    "            return MultilayerDict(_new_names_keys, self.dictionary)\n",
    "\n",
    "    def extend(self, keys: List[List[int]], mds: List, inplace: bool = False):\n",
    "        if len(keys) != np.prod([len(_keys) for _keys in self.names_keys.values()]):\n",
    "            raise ValueError(\n",
    "                \"The number of MultilayerDict and size of object do not match.\"\n",
    "            )\n",
    "        if len(keys) != len(mds):\n",
    "            raise ValueError(\"number of keys and mds do not match.\")\n",
    "\n",
    "        if inplace:\n",
    "            # dictionary\n",
    "            for _keys, _md in zip(keys, mds):\n",
    "                self.update(_keys, _md.dictionary)\n",
    "            # namesを延長\n",
    "            self.names.extend(mds[0].names)\n",
    "            # keysを延長\n",
    "            self.names_keys.update(mds[0].names_keys)\n",
    "        else:\n",
    "            md_return = copy.deepcopy(self)\n",
    "            # dictionary\n",
    "            for _keys, _md in zip(keys, mds):\n",
    "                md_return.update(_keys, _md.dictionary)\n",
    "            # namesを延長\n",
    "            md_return.names.extend(mds[0].names)\n",
    "            # keysを延長\n",
    "            md_return.names_keys.update(mds[0].names_keys)\n",
    "            return md_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dd50b562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:41.624186Z",
     "start_time": "2023-02-25T05:38:41.620802Z"
    }
   },
   "outputs": [],
   "source": [
    "d = MultilayerDict(names_keys=names_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "043d9eaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:41.856032Z",
     "start_time": "2023-02-25T05:38:41.850788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col', 'ind', 'ind2']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.names_keys.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1742fdd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:42.633437Z",
     "start_time": "2023-02-25T05:38:42.628764Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in itertools.product(*d.names_keys.values()):\n",
    "    d.update(i, {\"s\":\"t\", \"u\": \"w\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a16735dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:48.597930Z",
     "start_time": "2023-02-25T05:38:48.593517Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d =d.add_names(names_keys={\"new\":[\"s\", \"u\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "415f28e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:49.099507Z",
     "start_time": "2023-02-25T05:38:49.092767Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': {'dim1': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim2': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim3': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim4': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}}},\n",
       " 'b': {'dim1': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim2': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim3': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim4': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}}},\n",
       " 'c': {'dim1': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim2': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim3': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}},\n",
       "  'dim4': {1: {'s': 't', 'u': 'w'},\n",
       "   2: {'s': 't', 'u': 'w'},\n",
       "   3: {'s': 't', 'u': 'w'}}}}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cfbc56b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:38:57.121012Z",
     "start_time": "2023-02-25T05:38:57.116604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col': ['a', 'b', 'c'],\n",
       " 'ind': ['dim1', 'dim2', 'dim3', 'dim4'],\n",
       " 'ind2': [1, 2, 3],\n",
       " 'new': ['s', 'u']}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.names_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3e502207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T05:39:03.755150Z",
     "start_time": "2023-02-25T05:39:03.749924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col', 'ind', 'ind2', 'new']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"a\", \"dim1\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "86b3172d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T03:15:45.526368Z",
     "start_time": "2023-02-25T03:15:45.518772Z"
    }
   },
   "outputs": [],
   "source": [
    "for keys in d.names_keys[\"col\"]:\n",
    "    for key in keys:\n",
    "        df = pd.DataFrame(d.dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "84643f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T03:15:49.614520Z",
     "start_time": "2023-02-25T03:15:49.601553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dim1  dim2  dim3  dim4\n",
       "1     1     1     1     1\n",
       "2     1     1     1     1\n",
       "3     1     1     1     1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b8fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
